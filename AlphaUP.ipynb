{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#1. Importacion de librerias necesarias para la construccion del juego "
      ],
      "metadata": {
        "id": "bH7wypXbnCvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "np.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qzo-4OQRnURr",
        "outputId": "19461c2f-bbe9-445d-a8c0-5b89aeb5c078"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.22.4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Como funciona el juego del TICTACTOE\n",
        "\n",
        "¡Por supuesto! El Tic Tac Toe, también conocido como Tres en raya, es un juego de lápiz y papel para dos jugadores, que se juega en una cuadrícula de 3x3. El objetivo del juego es ser el primer jugador en conseguir tres símbolos en línea, ya sea de manera horizontal, vertical o diagonal.\n",
        "\n",
        "Reglas del juego:\n",
        "\n",
        "    El juego se juega en una cuadrícula de 3x3.\n",
        "\n",
        "    Dos jugadores eligen un símbolo, generalmente una \"X\" y un \"O\", y se turnan para colocar su símbolo en un cuadrado vacío de la cuadrícula.\n",
        "\n",
        "    El primer jugador que consiga colocar tres símbolos consecutivos en línea, ya sea horizontal, vertical o diagonal, gana el juego.\n",
        "\n",
        "    Si se llenan todas las casillas y ningún jugador ha conseguido tres símbolos en línea, el juego termina en empate.\n",
        "\n",
        "Cómo jugar:\n",
        "\n",
        "    Dibuja una cuadrícula de 3x3 en una hoja de papel o en cualquier superficie plana.\n",
        "\n",
        "    Elige un jugador para ser el primero en colocar su símbolo en la cuadrícula.\n",
        "\n",
        "    El jugador seleccionado coloca su símbolo en cualquier casilla vacía de la cuadrícula.\n",
        "\n",
        "    El otro jugador, a continuación, coloca su símbolo en cualquier otra casilla vacía.\n",
        "\n",
        "    Los jugadores siguen alternando turnos hasta que uno de ellos consiga colocar tres símbolos consecutivos en línea, o se llenen todas las casillas y no haya ganador.\n",
        "\n",
        "    Si un jugador consigue tres símbolos en línea, ese jugador gana el juego. Si se llenan todas las casillas y ningún jugador ha conseguido tres símbolos en línea, el juego termina en empate.\n",
        "\n",
        "    Si quieres jugar otra ronda, comienza de nuevo con el otro jugador comenzando la partida.\n",
        "\n",
        "Ejemplo de juego:\n",
        "\n",
        "    Se dibuja una cuadrícula de 3x3.\n",
        "\n",
        "| |\n",
        "| |\n",
        "\n",
        "| |\n",
        "\n",
        "    El jugador 1 elige colocar su símbolo \"X\" en la casilla central.\n",
        "\n",
        "| |\n",
        "| X |\n",
        "\n",
        "| |\n",
        "\n",
        "    El jugador 2 coloca su símbolo \"O\" en una casilla vacía.\n",
        "\n",
        "| |\n",
        "| X |\n",
        "\n",
        "| | O\n",
        "\n",
        "    Los jugadores siguen alternando turnos hasta que uno de ellos consiga colocar tres símbolos consecutivos en línea, o se llenen todas las casillas y no haya ganador.\n",
        "\n",
        "¡Eso es todo! Espero que hayas entendido las reglas y cómo jugar al Tic Tac Toe. ¡Diviértete jugando!"
      ],
      "metadata": {
        "id": "gPVqVCjZn6i9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Programacion del Mismo para luego entrenarlo al modelo "
      ],
      "metadata": {
        "id": "4Q-XjyLRoGZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos una clase llamada TresEnRaya\n",
        "class TresEnRaya:\n",
        "    # Inicializamos las variables de la clase\n",
        "    def __init__(self):\n",
        "        self.num_filas = 3  # número de filas del tablero\n",
        "        self.num_columnas = 3  # número de columnas del tablero\n",
        "        self.tamano_accion = self.num_filas * self.num_columnas  # número total de casillas en el tablero\n",
        "        \n",
        "    # Definimos una función para obtener el estado inicial del juego\n",
        "    def obtener_estado_inicial(self):\n",
        "        return np.zeros((self.num_filas, self.num_columnas))\n",
        "    \n",
        "    # Definimos una función para obtener el siguiente estado del juego después de una jugada\n",
        "    def obtener_siguiente_estado(self, estado_actual, accion, jugador):\n",
        "        fila = accion // self.num_columnas  # fila correspondiente a la casilla elegida\n",
        "        columna = accion % self.num_columnas  # columna correspondiente a la casilla elegida\n",
        "        estado_actual[fila, columna] = jugador  # colocamos el símbolo del jugador actual en la casilla elegida\n",
        "        return estado_actual\n",
        "    \n",
        "    # Definimos una función para obtener las jugadas válidas en el estado actual del juego\n",
        "    def obtener_jugadas_validas(self, estado_actual):\n",
        "        return (estado_actual.reshape(-1) == 0).astype(np.uint8)\n",
        "    \n",
        "    # Definimos una función para comprobar si alguien ha ganado después de una jugada\n",
        "    def comprobar_victoria(self, estado_actual, accion):\n",
        "        fila = accion // self.num_columnas  # fila correspondiente a la casilla elegida\n",
        "        columna = accion % self.num_columnas  # columna correspondiente a la casilla elegida\n",
        "        jugador = estado_actual[fila, columna]  # símbolo del jugador actual\n",
        "        \n",
        "        # Comprobamos si el jugador actual ha ganado en alguna fila, columna o diagonal\n",
        "        return (\n",
        "            np.sum(estado_actual[fila, :]) == jugador * self.num_columnas\n",
        "            or np.sum(estado_actual[:, columna]) == jugador * self.num_filas\n",
        "            or np.sum(np.diag(estado_actual)) == jugador * self.num_filas\n",
        "            or np.sum(np.diag(np.flip(estado_actual, axis=0))) == jugador * self.num_filas\n",
        "        )\n",
        "    \n",
        "    # Definimos una función para obtener el valor del juego después de una jugada y si el juego ha terminado o no\n",
        "    def obtener_valor_y_terminado(self, estado_actual, accion):\n",
        "        if self.comprobar_victoria(estado_actual, accion):\n",
        "            return 1, True  # el jugador actual ha ganado y el juego ha terminado\n",
        "        if np.sum(self.obtener_jugadas_validas(estado_actual)) == 0:\n",
        "            return 0, True  # el juego ha terminado en empate\n",
        "        return 0, False  # el juego no ha terminado\n",
        "    \n",
        "    # Definimos una función para obtener el jugador opuesto al jugador actual\n",
        "    def obtener_oponente(self, jugador):\n",
        "        return -jugador"
      ],
      "metadata": {
        "id": "972dXkkZoMM0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Para explicar el codigo hecho hasta ahora hay tres variables importantes que son las siguientes \n",
        "\n",
        "\n",
        "En este código, las variables son las siguientes:\n",
        "\n",
        "    num_filas: Un entero que representa el número de filas en el tablero del juego.\n",
        "\n",
        "    num_columnas: Un entero que representa el número de columnas en el tablero del juego.\n",
        "\n",
        "    estado_actual: Una matriz que representa el estado actual del juego.\n",
        "\n",
        "    accion: Un entero que representa la casilla elegida por el jugador actual para colocar su símbolo.\n",
        "\n",
        "    jugador: Un entero que representa el jugador actual que está haciendo la jugada.\n",
        "\n",
        "    obtener_estado_inicial: Una función que devuelve el estado inicial del juego.\n",
        "\n",
        "    obtener_siguiente_estado: Una función que devuelve el siguiente estado del juego después de una jugada.\n",
        "\n",
        "    obtener_jugadas_validas: Una función que devuelve una lista de jugadas válidas en el estado actual del juego.\n",
        "\n",
        "    comprobar_victoria: Una función que comprueba si el jugador actual ha ganado después de hacer una jugada.\n",
        "\n",
        "    obtener_valor_y_terminado: Una función que devuelve el valor del juego después de una jugada y si el juego ha terminado o no.\n",
        "\n",
        "    obtener_oponente: Una función que devuelve el jugador opuesto al jugador actual."
      ],
      "metadata": {
        "id": "ll2WXdfnpW-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos una instancia del juego de Tres en Raya\n",
        "tres_en_raya = TresEnRaya()\n",
        "\n",
        "# Inicializamos las variables\n",
        "jugador_actual = 1  # el jugador 1 empieza primero\n",
        "estado_actual = tres_en_raya.obtener_estado_inicial()\n",
        "\n",
        "# Bucle principal del juego\n",
        "while True:\n",
        "    # Imprimimos el estado actual del juego\n",
        "    print(estado_actual)\n",
        "    \n",
        "    # Obtenemos las jugadas válidas en el estado actual\n",
        "    jugadas_validas = tres_en_raya.obtener_jugadas_validas(estado_actual)\n",
        "    \n",
        "    # Imprimimos las jugadas válidas\n",
        "    print(\"jugadas válidas\", [i for i in range(tres_en_raya.tamano_accion) if jugadas_validas[i] == 1])\n",
        "    \n",
        "    # Le pedimos al jugador actual que elija una jugada\n",
        "    accion = int(input(f\"Jugador {jugador_actual}:\"))\n",
        "    \n",
        "    # Comprobamos si la jugada elegida es válida\n",
        "    if jugadas_validas[accion] == 0:\n",
        "        print(\"jugada no válida\")\n",
        "        continue  # si la jugada no es válida, volvemos a pedir al jugador actual que elija una jugada\n",
        "    \n",
        "    # Actualizamos el estado del juego después de la jugada\n",
        "    estado_actual = tres_en_raya.obtener_siguiente_estado(estado_actual, accion, jugador_actual)\n",
        "    \n",
        "    # Obtenemos el valor del juego después de la jugada y si el juego ha terminado o no\n",
        "    valor, terminado = tres_en_raya.obtener_valor_y_terminado(estado_actual, accion)\n",
        "    \n",
        "    # Si el juego ha terminado, imprimimos el estado final del juego y el resultado\n",
        "    if terminado:\n",
        "        print(estado_actual)\n",
        "        if valor == 1:\n",
        "            print(f\"¡Jugador {jugador_actual} ha ganado!\")\n",
        "        else:\n",
        "            print(\"¡Empate!\")\n",
        "        break  # salimos del bucle principal del juego\n",
        "    \n",
        "    # Si el juego no ha terminado, pasamos al jugador opuesto\n",
        "    jugador_actual = tres_en_raya.obtener_oponente(jugador_actual)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKL8dCdNpx2k",
        "outputId": "c202d557-e1cc-453e-dc49-ff02f331f966"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "jugadas válidas [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
            "Jugador 1:2\n",
            "[[0. 0. 1.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "jugadas válidas [0, 1, 3, 4, 5, 6, 7, 8]\n",
            "Jugador -1:3\n",
            "[[ 0.  0.  1.]\n",
            " [-1.  0.  0.]\n",
            " [ 0.  0.  0.]]\n",
            "jugadas válidas [0, 1, 4, 5, 6, 7, 8]\n",
            "Jugador 1:1\n",
            "[[ 0.  1.  1.]\n",
            " [-1.  0.  0.]\n",
            " [ 0.  0.  0.]]\n",
            "jugadas válidas [0, 4, 5, 6, 7, 8]\n",
            "Jugador -1:4\n",
            "[[ 0.  1.  1.]\n",
            " [-1. -1.  0.]\n",
            " [ 0.  0.  0.]]\n",
            "jugadas válidas [0, 5, 6, 7, 8]\n",
            "Jugador 1:8\n",
            "[[ 0.  1.  1.]\n",
            " [-1. -1.  0.]\n",
            " [ 0.  0.  1.]]\n",
            "jugadas válidas [0, 5, 6, 7]\n",
            "Jugador -1:6\n",
            "[[ 0.  1.  1.]\n",
            " [-1. -1.  0.]\n",
            " [-1.  0.  1.]]\n",
            "jugadas válidas [0, 5, 7]\n",
            "Jugador 1:0\n",
            "[[ 1.  1.  1.]\n",
            " [-1. -1.  0.]\n",
            " [-1.  0.  1.]]\n",
            "¡Jugador 1 ha ganado!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Desarrollamos mejor la interfaz de usuario para entende rlo que estamos haciendo vamos a explicar las variables claves del juego \n",
        "\n",
        "\n",
        "En este código, las variables son las siguientes:\n",
        "\n",
        "    juego_tictactoe: Un objeto que representa el juego de Tic Tac Toe.\n",
        "\n",
        "    jugador_actual: Un entero que representa el jugador que tiene el turno en ese momento. Puede ser 1 o 2.\n",
        "\n",
        "    estado_actual: Una lista de 9 elementos que representa el estado actual del tablero del juego.\n",
        "\n",
        "    jugadas_validas: Una lista de 9 elementos que indica las casillas donde se pueden colocar símbolos en el estado actual del juego.\n",
        "\n",
        "    accion: Un entero que representa la casilla elegida por el jugador actual para colocar su símbolo.\n",
        "\n",
        "    valor: Un entero que representa el resultado del juego. Puede ser 1 (si el jugador 1 ha ganado), -1 (si el jugador 2 ha ganado) o 0 (si el juego ha terminado en empate).\n",
        "\n",
        "    terminado: Un booleano que indica si el juego ha terminado o no."
      ],
      "metadata": {
        "id": "pOUMGtuyrSKn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Una vez tenido el juego lo que tenemos que programar es el Algoritmo MCTS de Machine Learning \n",
        "\n",
        "El MCTS es un algoritmo de búsqueda utilizado en inteligencia artificial para encontrar la mejor jugada en un juego determinado. El algoritmo construye un árbol de búsqueda que representa todas las posibles jugadas que se pueden hacer en el juego, y utiliza simulaciones aleatorias para estimar la calidad de cada jugada.\n",
        "\n",
        "El algoritmo se compone de cuatro fases principales:\n",
        "\n",
        "    Selección: Se comienza en la raíz del árbol y se desciende por los nodos del árbol seleccionando aquellos que maximizan la relación exploración/explotación (balance entre explorar nuevas jugadas y explotar las mejores jugadas conocidas). Esta selección se realiza mediante la utilización de una función denominada UCT (Upper Confidence Bound applied to Trees).\n",
        "\n",
        "    Expansión: Una vez se llega a un nodo hoja del árbol (un nodo que no tiene hijos), se expande el árbol añadiendo un nuevo nodo hijo que representa una jugada no explorada.\n",
        "\n",
        "    Simulación: A partir del nuevo nodo hijo, se realiza una simulación aleatoria del juego hasta que se alcance un estado final (ganar, perder o empatar).\n",
        "\n",
        "    Retropropagación: Se actualizan las estadísticas de cada nodo visitado durante la selección y expansión de acuerdo con el resultado de la simulación. Esto se hace propagando hacia arriba la información sobre el resultado de la simulación.\n",
        "\n",
        "Después de varias iteraciones de estas cuatro fases, se obtiene un árbol de búsqueda que representa todas las posibles jugadas y su calidad estimada. La mejor jugada se elige en función de las estadísticas de los nodos del árbol, como la frecuencia de visitas y la calidad estimada.\n",
        "\n",
        "En resumen, el MCTS es un algoritmo de búsqueda que utiliza simulaciones aleatorias para estimar la calidad de las jugadas en un juego determinado. Es utilizado en inteligencia artificial para encontrar la mejor jugada y construye un árbol de búsqueda que representa todas las posibles jugadas y su calidad estimada. El árbol es construido de forma incremental mediante la selección, expansión, simulación y retropropagación de estadísticas a lo largo de las iteraciones del algoritmo."
      ],
      "metadata": {
        "id": "HwjyqaUsutuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math"
      ],
      "metadata": {
        "id": "mtZrpoOzvpBc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tenemso que refactorizar la clase TicTacToe"
      ],
      "metadata": {
        "id": "viq6DxViv1ve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TresEnRaya:\n",
        "  def __init__(self):\n",
        "    # Inicializa el tamaño del juego de tres en raya con tres filas y tres columnas,\n",
        "    # así como el tamaño de la acción (número total de casillas).\n",
        "    self.filas = 3\n",
        "    self.columnas = 3\n",
        "    self.tamanio_accion = self.filas * self.columnas\n",
        "    \n",
        "  def get_estado_inicial(self):\n",
        "    # Devuelve un estado inicial vacío (todos los valores son cero).\n",
        "    return np.zeros((self.filas, self.columnas))\n",
        "\n",
        "  def obtener_siguiente_estado(self, estado, accion, jugador):\n",
        "    # Actualiza el estado con la acción tomada por el jugador y devuelve el nuevo estado.\n",
        "    fila = accion // self.columnas\n",
        "    columna = accion % self.columnas\n",
        "    estado[fila, columna] = jugador\n",
        "    return estado\n",
        "\n",
        "  def obtener_movimientos_validos(self, estado):\n",
        "    # Devuelve una matriz booleana que indica qué movimientos son válidos en el estado actual.\n",
        "    return (estado.reshape(-1) == 0).astype(np.uint8)\n",
        "\n",
        "  def verificar_victoria(self, estado, accion):\n",
        "    # Verifica si la acción ha llevado a una victoria del jugador que ha realizado la acción.\n",
        "    # Devuelve verdadero si es así, falso en caso contrario.\n",
        "    if accion is None:\n",
        "        return False\n",
        "    \n",
        "    fila = accion // self.columnas\n",
        "    columna = accion % self.columnas\n",
        "    jugador = estado[fila, columna]\n",
        "    \n",
        "    return (\n",
        "        np.sum(estado[fila, :]) == jugador * self.columnas\n",
        "        or np.sum(estado[:, columna]) == jugador * self.filas\n",
        "        or np.sum(np.diag(estado)) == jugador * self.filas\n",
        "        or np.sum(np.diag(np.flip(estado, axis=0))) == jugador * self.filas\n",
        "    )\n",
        "\n",
        "  def obtener_valor_y_terminado(self, estado, accion):\n",
        "    # Devuelve el valor del juego (-1 para la derrota, 0 para el empate y 1 para la victoria) \n",
        "    # y un indicador booleano que indica si el juego ha terminado después de que se realizara la acción.\n",
        "    if self.verificar_victoria(estado, accion):\n",
        "        return 1, True\n",
        "    if np.sum(self.obtener_movimientos_validos(estado)) == 0:\n",
        "        return 0, True\n",
        "    return 0, False\n",
        "\n",
        "  def obtener_oponente(self, jugador):\n",
        "    # Devuelve el jugador opuesto.\n",
        "    return -jugador\n",
        "\n",
        "  def obtener_valor_oponente(self, valor):\n",
        "    # Devuelve el valor del oponente.\n",
        "    return -valor\n",
        "\n",
        "  def cambiar_perspectiva(self, estado, jugador):\n",
        "    # Cambia de perspectiva según el jugador.\n",
        "    return estado * jugador\n"
      ],
      "metadata": {
        "id": "oaDHSU8LwWVl"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Básicamente, esta clase representa el juego de Tres en Raya y tiene varias funciones para manejar el estado del juego. Los nombres de las variables son descriptivos de su función:\n",
        "\n",
        "    tamano_fila y tamano_columna: representan el tamaño de la cuadrícula del juego.\n",
        "    tamano_accion: representa el número total de acciones posibles en el juego.\n",
        "    obtener_estado_inicial: devuelve el estado inicial del juego.\n",
        "    obtener_siguiente_estado: toma un estado y una acción y devuelve el siguiente estado después de aplicar la acción.\n",
        "    obtener_jugadas_validas: toma un estado y devuelve las acciones válidas en ese estado.\n",
        "    comprobar_victoria: toma un estado y una acción y comprueba si la acción ha resultado en una victoria para el jugador que la ha realizado.\n",
        "    obtener_valor_y_terminado: toma un estado y una acción y devuelve el valor del juego después de aplicar la acción y si el juego ha terminado o no.\n",
        "    obtener_oponente: toma un jugador y devuelve el jugador opuesto.\n",
        "    obtener_valor_oponente: toma un valor y devuelve su valor opuesto.\n",
        "    cambiar_perspectiva: toma un estado y un jugador y devuelve el estado cambiado de perspectiva"
      ],
      "metadata": {
        "id": "jC7L0q98xqkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Nodo:\n",
        "    def __init__(self, juego, args, estado, padre=None, accion=None):\n",
        "        self.juego = juego\n",
        "        self.args = args\n",
        "        self.estado = estado\n",
        "        self.padre = padre\n",
        "        self.accion = accion\n",
        "        \n",
        "        self.hijos = []\n",
        "        self.movimientos_expansibles = juego.obtener_movimientos_validos(estado)\n",
        "        \n",
        "        self.num_visitas = 0\n",
        "        self.suma_valor = 0\n",
        "        \n",
        "    def esta_totalmente_expandido(self):\n",
        "        return np.sum(self.movimientos_expansibles) == 0 and len(self.hijos) > 0\n",
        "    \n",
        "    def seleccionar_hijo(self):\n",
        "        mejor_hijo = None\n",
        "        mejor_ucb = -np.inf\n",
        "        \n",
        "        for hijo in self.hijos:\n",
        "            ucb = self.obtener_ucb(hijo)\n",
        "            if ucb > mejor_ucb:\n",
        "                mejor_hijo = hijo\n",
        "                mejor_ucb = ucb\n",
        "                \n",
        "        return mejor_hijo\n",
        "    \n",
        "    def obtener_ucb(self, hijo):\n",
        "        valor_q = 1 - ((hijo.suma_valor / hijo.num_visitas) + 1) / 2\n",
        "        return valor_q + self.args['C'] * math.sqrt(math.log(self.num_visitas) / hijo.num_visitas)\n",
        "    \n",
        "    def expandir(self):\n",
        "        accion = np.random.choice(np.where(self.movimientos_expansibles == 1)[0])\n",
        "        self.movimientos_expansibles[accion] = 0\n",
        "        \n",
        "        estado_hijo = self.estado.copy()\n",
        "        estado_hijo = self.juego.obtener_siguiente_estado(estado_hijo, accion, 1)\n",
        "        estado_hijo = self.juego.cambiar_perspectiva(estado_hijo, jugador=-1)\n",
        "        \n",
        "        hijo = Nodo(self.juego, self.args, estado_hijo, self, accion)\n",
        "        self.hijos.append(hijo)\n",
        "        return hijo\n",
        "    \n",
        "    def simular(self):\n",
        "        valor, es_terminal = self.juego.obtener_valor_y_terminado(self.estado, self.accion)\n",
        "        valor = self.juego.obtener_valor_oponente(valor)\n",
        "        \n",
        "        if es_terminal:\n",
        "            return valor\n",
        "        \n",
        "        estado_rolout = self.estado.copy()\n",
        "        jugador_rolout = 1\n",
        "        while True:\n",
        "            movimientos_validos = self.juego.obtener_movimientos_validos(estado_rolout)\n",
        "            accion = np.random.choice(np.where(movimientos_validos == 1)[0])\n",
        "            estado_rolout = self.juego.obtener_siguiente_estado(estado_rolout, accion, jugador_rolout)\n",
        "            valor, es_terminal = self.juego.obtener_valor_y_terminado(estado_rolout, accion)\n",
        "            if es_terminal:\n",
        "                if jugador_rolout == -1:\n",
        "                    valor = self.juego.obtener_valor_oponente(valor)\n",
        "                return valor    \n",
        "            \n",
        "            jugador_rolout = self.juego.obtener_oponente(jugador_rolout)\n",
        "            \n",
        "    def retropropagar(self, valor):\n",
        "        self.suma_valor += valor\n",
        "        self.num_visitas += 1\n",
        "        \n",
        "        valor = self.juego.obtener_valor_oponente(valor)\n",
        "        if self.padre is not None:\n",
        "            self.padre.retropropagar(valor)"
      ],
      "metadata": {
        "id": "0xgUPAJxxr6q"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta es la clase Nodo que se utiliza en el algoritmo MCTS. Aquí se define un nodo en el árbol de búsqueda. Un nodo tiene un estado (representado como una matriz), un padre, una acción tomada para llegar al estado, una lista de hijos (que son otros nodos) y el recuento de visitas y valor acumulado para los nodos en este camino.\n",
        "\n",
        "La función __init__() inicializa un nodo con el estado, el juego y los argumentos dados. Se establece la lista de hijos y movimientos aún no explorados en este nodo.\n",
        "\n",
        "is_fully_expanded() verifica si el nodo tiene todos los movimientos disponibles explorados.\n",
        "\n",
        "select() selecciona el hijo con el mejor valor de UCB (Upper Confidence Bound). El valor UCB se calcula en la función get_ucb() y se utiliza para equilibrar la exploración y explotación del árbol.\n",
        "\n",
        "expand() agrega un nuevo nodo hijo al nodo actual y lo devuelve.\n",
        "\n",
        "simulate() realiza una simulación (o rollout) desde el estado actual hasta el final del juego. Se utilizan jugadas aleatorias para avanzar en el juego y se devuelve el valor final del estado resultante.\n",
        "\n",
        "backpropagate() actualiza los recuentos de visitas y el valor acumulado a lo largo del camino que llevó a este nodo y sus padres. Esto se hace recursivamente a través de la función backpropagate()."
      ],
      "metadata": {
        "id": "IhkDIHSrxz9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MCTS:\n",
        "    def __init__(self, juego, args):\n",
        "        self.juego = juego\n",
        "        self.args = args\n",
        "        \n",
        "    def buscar(self, estado):\n",
        "        raiz = Nodo(self.juego, self.args, estado)\n",
        "        \n",
        "        for busqueda in range(self.args['num_searches']):\n",
        "            nodo = raiz\n",
        "            \n",
        "            while nodo.esta_totalmente_expandido():\n",
        "                nodo = nodo.seleccionar_hijo()\n",
        "                \n",
        "            valor, es_terminal = self.juego.obtener_valor_y_terminado(nodo.estado, nodo.accion)\n",
        "            valor = self.juego.obtener_valor_oponente(valor)\n",
        "            \n",
        "            if not es_terminal:\n",
        "                nodo = nodo.expandir()\n",
        "                valor = nodo.simular()\n",
        "                \n",
        "            nodo.retropropagar(valor)    \n",
        "            \n",
        "            \n",
        "        probabilidades_accion = np.zeros(self.juego.tamanio_accion)\n",
        "        for hijo in raiz.hijos:\n",
        "            probabilidades_accion[hijo.accion] = hijo.num_visitas\n",
        "        probabilidades_accion /= np.sum(probabilidades_accion)\n",
        "        return probabilidades_accion"
      ],
      "metadata": {
        "id": "0_3SwZDcyiV-"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La clase MCTS implementa el algoritmo Monte Carlo Tree Search (MCTS) para un juego dado. Este algoritmo se utiliza para encontrar la mejor jugada posible en un juego, utilizando una técnica de simulación de juegos repetitiva y la construcción de un árbol de búsqueda de todas las posibles jugadas.\n",
        "\n",
        "La clase MCTS tiene un método llamado search, que toma un estado actual del juego y realiza un número de búsquedas (definido por num_searches en los argumentos) para construir el árbol de búsqueda. En cada búsqueda, el algoritmo recorre el árbol y selecciona un nodo que aún no esté completamente expandido. Luego, el algoritmo puede expandir el nodo seleccionado, simular un juego completo desde ese estado y propagar el resultado de la simulación hacia arriba a través del árbol.\n",
        "\n",
        "Finalmente, después de completar todas las búsquedas, el método search devuelve una matriz de probabilidades de acciones, que representa la probabilidad de elegir cada posible acción desde el estado de entrada, dada la búsqueda realizada.\n",
        "\n",
        "En resumen, la clase MCTS proporciona una forma sistemática de buscar y encontrar la mejor jugada posible en un juego dado."
      ],
      "metadata": {
        "id": "BPIG9vjxyj17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tictactoe = TresEnRaya()\n",
        "jugador = 1\n",
        "\n",
        "args = {\n",
        "    'C': 1.41,\n",
        "    'num_searches': 1000\n",
        "}\n",
        "\n",
        "mcts = MCTS(tictactoe, args)\n",
        "\n",
        "estado = tictactoe.get_estado_inicial()\n",
        "\n",
        "while True:\n",
        "    print(estado)\n",
        "    \n",
        "    if jugador == 1:\n",
        "        movimientos_validos = tictactoe.obtener_movimientos_validos(estado)\n",
        "        print(\"movimientos_validos\", [i for i in range(tictactoe.tamanio_accion) if movimientos_validos[i] == 1])\n",
        "        accion = int(input(f\"{jugador}:\"))\n",
        "\n",
        "        if movimientos_validos[accion] == 0:\n",
        "            print(\"acción no válida\")\n",
        "            continue\n",
        "            \n",
        "    else:\n",
        "        estado_neutro = tictactoe.cambiar_perspectiva(estado, jugador)\n",
        "        mcts_probs = mcts.buscar(estado_neutro)\n",
        "        accion = np.argmax(mcts_probs)\n",
        "        \n",
        "    estado = tictactoe.obtener_siguiente_estado(estado, accion, jugador)\n",
        "    \n",
        "    valor, es_terminal = tictactoe.obtener_valor_y_terminado(estado, accion)\n",
        "    \n",
        "    if es_terminal:\n",
        "        print(estado)\n",
        "        if valor == 1:\n",
        "            print(jugador, \"ganó\")\n",
        "        else:\n",
        "            print(\"empate\")\n",
        "        break\n",
        "        \n",
        "    jugador = tictactoe.obtener_oponente(jugador)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJkLNw_0zC8D",
        "outputId": "e6dacc52-87d3-45fe-bac8-ad7f2530b940"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "movimientos_validos [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
            "1:1\n",
            "[[0. 1. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "[[ 0.  1.  0.]\n",
            " [ 0. -1.  0.]\n",
            " [ 0.  0.  0.]]\n",
            "movimientos_validos [0, 2, 3, 5, 6, 7, 8]\n",
            "1:8\n",
            "[[ 0.  1.  0.]\n",
            " [ 0. -1.  0.]\n",
            " [ 0.  0.  1.]]\n",
            "[[ 0.  1.  0.]\n",
            " [ 0. -1. -1.]\n",
            " [ 0.  0.  1.]]\n",
            "movimientos_validos [0, 2, 3, 6, 7]\n",
            "1:2\n",
            "[[ 0.  1.  1.]\n",
            " [ 0. -1. -1.]\n",
            " [ 0.  0.  1.]]\n",
            "[[ 0.  1.  1.]\n",
            " [-1. -1. -1.]\n",
            " [ 0.  0.  1.]]\n",
            "-1 ganó\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código implementa un juego de TresEnRaya en el que uno de los jugadores utiliza el algoritmo MCTS para seleccionar sus movimientos.\n",
        "\n",
        "En la primera parte del código, se crea una instancia del juego TresEnRaya, se define que el jugador 1 empezará el juego y se establecen los parámetros para el algoritmo MCTS. Luego se crea una instancia de la clase MCTS utilizando la instancia del juego TresEnRaya y los parámetros definidos anteriormente. Se obtiene el estado inicial del juego utilizando el método get_initial_state del juego TresEnRaya.\n",
        "\n",
        "Luego, en el bucle while, se imprime el estado actual del juego y se obtienen los movimientos válidos para el jugador actual. Si el jugador actual es el jugador 1, se imprimen los movimientos válidos y se le pide al usuario que seleccione uno. Si el movimiento no es válido, se imprime un mensaje de error y se continúa con el bucle while. Si el jugador actual es el jugador 2, se llama al método search de la instancia de la clase MCTS para obtener las probabilidades de los posibles movimientos a realizar. Luego, se selecciona el movimiento con la mayor probabilidad utilizando np.argmax.\n",
        "\n",
        "A continuación, se actualiza el estado del juego utilizando el movimiento seleccionado por el jugador actual y se obtiene el valor y el estado terminal del juego después de realizar este movimiento utilizando el método get_value_and_terminated del juego TresEnRaya.\n",
        "\n",
        "Si el juego ha terminado, se imprime el estado final del juego y se imprime si el jugador actual ha ganado o si ha habido un empate. Si el juego no ha terminado, se cambia al siguiente jugador utilizando el método get_opponent del juego TresEnRaya."
      ],
      "metadata": {
        "id": "3vfjbKrQzEM5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo con su correpsondiente red neuronal "
      ],
      "metadata": {
        "id": "h0c0s9WY8F9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "print(np.__version__)\n",
        "import math\n",
        "\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCmAmPfQ8J8p",
        "outputId": "472496e6-b097-40e1-e0a5-4cd3bfdbe6be"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.22.4\n",
            "1.13.1+cu116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class TresEnRaya:\n",
        "    def __init__(self):\n",
        "        self.num_filas = 3\n",
        "        self.num_columnas = 3\n",
        "        self.tam_tablero = self.num_filas * self.num_columnas\n",
        "        \n",
        "    def obtener_estado_inicial(self):\n",
        "        return np.zeros((self.num_filas, self.num_columnas))\n",
        "    \n",
        "    def obtener_siguiente_estado(self, estado, accion, jugador):\n",
        "        fila = accion // self.num_columnas\n",
        "        columna = accion % self.num_columnas\n",
        "        estado[fila, columna] = jugador\n",
        "        return estado\n",
        "    \n",
        "    def obtener_movimientos_validos(self, estado):\n",
        "        return (estado.reshape(-1) == 0).astype(np.uint8)\n",
        "    \n",
        "    def comprobar_victoria(self, estado, accion):\n",
        "        if accion == None:\n",
        "            return False\n",
        "        \n",
        "        fila = accion // self.num_columnas\n",
        "        columna = accion % self.num_columnas\n",
        "        jugador = estado[fila, columna]\n",
        "        \n",
        "        return (\n",
        "            np.sum(estado[fila, :]) == jugador * self.num_columnas\n",
        "            or np.sum(estado[:, columna]) == jugador * self.num_filas\n",
        "            or np.sum(np.diag(estado)) == jugador * self.num_filas\n",
        "            or np.sum(np.diag(np.flip(estado, axis=0))) == jugador * self.num_filas\n",
        "        )\n",
        "    \n",
        "    def obtener_valor_y_terminado(self, estado, accion):\n",
        "        if self.comprobar_victoria(estado, accion):\n",
        "            return 1, True\n",
        "        if np.sum(self.obtener_movimientos_validos(estado)) == 0:\n",
        "            return 0, True\n",
        "        return 0, False\n",
        "    \n",
        "    def obtener_oponente(self, jugador):\n",
        "        return -jugador\n",
        "    \n",
        "    def obtener_valor_oponente(self, valor):\n",
        "        return -valor\n",
        "    \n",
        "    def cambiar_perspectiva(self, estado, jugador):\n",
        "        return estado * jugador\n",
        "    \n",
        "    def obtener_estado_codificado(self, estado):\n",
        "        estado_codificado = np.stack(\n",
        "            (estado == -1, estado == 0, estado == 1)\n",
        "        ).astype(np.float32)\n",
        "        \n",
        "        return estado_codificado\n"
      ],
      "metadata": {
        "id": "B0Wy9QLo8lQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, juego, num_bloques_residuales, num_ocultas):\n",
        "        super().__init__()\n",
        "        self.bloque_inicio = nn.Sequential(\n",
        "            nn.Conv2d(3, num_ocultas, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(num_ocultas),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        self.espina_dorsal = nn.ModuleList(\n",
        "            [BloqueResidual(num_ocultas) for i in range(num_bloques_residuales)]\n",
        "        )\n",
        "        \n",
        "        self.cabeza_politica = nn.Sequential(\n",
        "            nn.Conv2d(num_ocultas, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(32 * juego.numero_filas * juego.numero_columnas, juego.tamaño_acción)\n",
        "        )\n",
        "        \n",
        "        self.cabeza_valor = nn.Sequential(\n",
        "            nn.Conv2d(num_ocultas, 3, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(3),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(3 * juego.numero_filas * juego.numero_columnas, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.bloque_inicio(x)\n",
        "        for bloque_res in self.espina_dorsal:\n",
        "            x = bloque_res(x)\n",
        "        politica = self.cabeza_politica(x)\n",
        "        valor = self.cabeza_valor(x)\n",
        "        return politica, valor\n",
        "    \n",
        "class BloqueResidual(nn.Module):\n",
        "    def __init__(self, num_ocultas):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(num_ocultas, num_ocultas, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(num_ocultas)\n",
        "        self.conv2 = nn.Conv2d(num_ocultas, num_ocultas, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(num_ocultas)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.bn2(self.conv2(x))\n",
        "        x += residual\n",
        "        x = F.relu(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "crNH2JyD-Pa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clase ResNet\n",
        "\n",
        "ResNet es una clase que hereda de la clase nn.Module de PyTorch. Representa una red neuronal convolucional que se utiliza para juegos y otros tipos de tareas. El objetivo de esta clase es construir una red neuronal que pueda aprender a jugar juegos mediante el aprendizaje por refuerzo. La arquitectura de esta red neuronal es una ResNet (red neuronal residual) que consiste en bloques residuales.\n",
        "\n",
        "La clase ResNet tiene varios métodos. El método __init__ es el constructor que inicializa los parámetros de la red neuronal. Recibe tres argumentos: juego, num_bloques_residuales y num_ocultas. juego es un objeto que representa el juego en el que se entrenará la red neuronal. num_bloques_residuales es el número de bloques residuales que tendrá la red neuronal y num_ocultas es el número de características o canales de cada bloque.\n",
        "\n",
        "El método forward realiza la propagación hacia adelante de la red neuronal. Recibe un tensor de entrada x y devuelve dos tensores: politica y valor. politica representa la política aprendida por la red neuronal y valor representa la estimación del valor del estado actual del juego.\n",
        "\n",
        "\n",
        "Clase BloqueResidual\n",
        "\n",
        "BloqueResidual es una clase que también hereda de nn.Module. Representa un bloque residual utilizado en la construcción de la red neuronal de la clase ResNet. El objetivo de esta clase es crear bloques residuales que permitan a la red neuronal aprender características más profundas y complejas.\n",
        "\n",
        "La clase BloqueResidual tiene dos métodos: __init__ y forward. El método __init__ es el constructor que inicializa los parámetros del bloque residual. Recibe un argumento num_ocultas, que es el número de características o canales del bloque.\n",
        "\n",
        "El método forward realiza la propagación hacia adelante del bloque residual. Recibe un tensor de entrada x y devuelve un tensor de salida x. El bloque residual se compone de dos capas de convolución y dos capas de normalización por lotes (batch normalization) que ayudan a estabilizar y acelerar el proceso de entrenamiento de la red neuronal.\n",
        "\n",
        "En resumen, ResNet y BloqueResidual son clases que se utilizan para construir una red neuronal convolucional que puede aprender a jugar juegos mediante el aprendizaje por refuerzo. La clase ResNet representa la red neuronal y la clase BloqueResidual representa los bloques residuales que se utilizan para construirla. Juntas, estas dos clases permiten construir una red neuronal que puede aprender a jugar juegos y otros tipos de tareas."
      ],
      "metadata": {
        "id": "CM0cUNQe-jP0"
      }
    }
  ]
}